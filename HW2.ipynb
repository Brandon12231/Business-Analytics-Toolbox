{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon12231/Business-Analytics-Toolbox/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework fit and select a classifier to predict credit card default using `default_of_credit_card_clients` dataset from BlackBoard course site. The data description is available at : https://www.kaggle.com/datasets/jishnukoliyadan/taiwan-default-credit-card-clients\n",
        "\n",
        "1. Explore (5+5+10=20 points)\n",
        "  1. load the dataset. Use only the columns \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", and \"AGE\" among predictors. The target is \"default payment next month\". \n",
        "  1. identify the categorical features (with brief explanation), and \n",
        "  1. produce the pairwise scatter plot only for the numeric variables. \n",
        "1. Prepare a pipeline to (30 points)\n",
        "  1. standardize the numeric attributes\n",
        "  1. expand the categorical attributes to columns of 0/1 variables\n",
        "  1. fit a `RandomForestClassifier` classifier\n",
        "1. Search over the `max_depth` and `min_samples_leaf` parameters to find the best model per **balanced accuracy** metric. Use at least three different search strategies and discuss any differences you see in the results. (20 points)\n",
        "1. Let's assume that the cost of missing a default (i.e., predicting non-default for a customer who ended up defaulting) is 10 times the cost of flagging a non-defaulter as defaulter. Let's further assume that the cost of correct predictions are 0. Use any one of the search strategies considered in the previous question to find the `RandomForestClassifier` that minimizes the cost. (20 points)\n",
        "1. Collaboration statement: Who did you discuss while answering this homework (whether to get or to provide help)? What questions/topics did you discuss? (10 points)\n",
        "\n",
        "Note: No penalty for either side. While getting help in figuring out how to solve is OK, all answers should be produced by you. \n"
      ],
      "metadata": {
        "id": "ZpvAo7MRpqUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_folder = '/content/drive/MyDrive/data/810/default_of_credit_card_clients.csv/'"
      ],
      "metadata": {
        "id": "wEfeyEvs6jqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_folder = '/content/drive/MyDrive/data/810/default_of_credit_card_clients.csv/'"
      ],
      "metadata": {
        "id": "YO2tWGlkXB46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data/810/default_of_credit_card_clients.csv')\n",
        "data.info()\n",
        "data.head(3)"
      ],
      "metadata": {
        "id": "u7PC41dxXG2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"default payment next month\"]]\n",
        "data"
      ],
      "metadata": {
        "id": "XaFTODIgYmdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size = .25, random_state=0)\n",
        "\n",
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "id": "t7bduN8GXvU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "id": "feoYl1VZX6Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"SEX\"].value_counts()"
      ],
      "metadata": {
        "id": "zVqBliS8X9DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"EDUCATION\"].value_counts()"
      ],
      "metadata": {
        "id": "5CY235NdYLh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"MARRIAGE\"].value_counts()"
      ],
      "metadata": {
        "id": "IpyH_C7sYTcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "data1=data[[\"LIMIT_BAL\",\"AGE\"]]\n",
        "sns.pairplot(data1, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind='scatter', diag_kind='hist', markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)\n"
      ],
      "metadata": {
        "id": "aL33LAnoYa1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2PdS8WUbo1v"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import set_config\n",
        "\n",
        "set_config(display='diagram') # shows the pipeline structure graphically\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse=False, drop=\"first\"))\n",
        "    ])"
      ],
      "metadata": {
        "id": "wKdktPeTdXOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "num_attribs = [\"LIMIT_BAL\",\"AGE\"]\n",
        "cat_attribs = [\"SEX\",\"EDUCATION\",\"MARRIAGE\"]\n",
        "\n",
        "# The following step patches SimpleImputer to produce feature names\n",
        "SimpleImputer.get_feature_names_out = StandardScaler.get_feature_names_out\n",
        "\n",
        "preprocess_pipeline = ColumnTransformer([ # handle each type of column with appropriate pipeline\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", cat_pipeline, cat_attribs),\n",
        "    ])\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline),\n",
        "    ('svm', SVC()),\n",
        "])"
      ],
      "metadata": {
        "id": "NbIkI8tQdb9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X = train_data.drop(\"default payment next month\", axis=1)\n",
        "df_y = train_data[\"default payment next month\"]\n",
        "print(df_X.head())  # to check that 'y' isn't included\n",
        "\n",
        "X_train = preprocess_pipeline.fit_transform(df_X)\n",
        "y_train = df_y.values\n",
        "preprocess_pipeline.get_feature_names_out() # check the column names produced by the pipeline"
      ],
      "metadata": {
        "id": "osbwj2cWdqv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "forest_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KicFx3Ssfb4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "X_test = preprocess_pipeline.transform(test_data)\n",
        "y_test = test_data[\"default payment next month\"]\n",
        "y_pred = forest_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "jVnzMcnHfvsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracy_score(y_test, y_pred).round(4)"
      ],
      "metadata": {
        "id": "fZqVBO6zf5dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "diUqDKkthR10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred);"
      ],
      "metadata": {
        "id": "GhdMmi7nhj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNVDCt18hrTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sW5RgZiE6pA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "RocCurveDisplay.from_estimator(forest_clf, X_test, y_test);"
      ],
      "metadata": {
        "id": "XcuGJsSsifZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10, scoring='balanced_accuracy')\n",
        "forest_scores.mean().round(3)"
      ],
      "metadata": {
        "id": "ijpJjL-pilqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "lr_pipe = make_pipeline(preprocess_pipeline, LogisticRegression())\n",
        "# we have to use data frames here because the preprocessing step expects them.\n",
        "lr_scores = cross_val_score(lr_pipe, df_X, df_y, cv=10, scoring='balanced_accuracy')\n",
        "lr_scores.mean().round(3)"
      ],
      "metadata": {
        "id": "SFLLyeO-iuy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRID\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [ \n",
        "    {'svm__C': np.logspace(-3, 3, 4), \n",
        "     'svm__gamma': np.logspace(-2, 2, 5)\n",
        "     }, \n",
        "    ]\n",
        "# Check what's in this parameter grid\n",
        "print('The parameter grid : ')\n",
        "print(param_grid)\n",
        "\n",
        "grid_search = GridSearchCV(full_pipeline, param_grid, cv=3, \n",
        "                                 scoring='balanced_accuracy')\n",
        "grid_search.fit(df_X, df_y)\n",
        "print('\\n\\nThe best parameters are ', grid_search.best_params_)\n",
        "\n",
        "grid_cv_res = pd.DataFrame(grid_search.cv_results_) # convert to DF for convenience\n",
        "grid_cv_res.sort_values(by='mean_test_score', ascending=False, inplace=True)  # sort the data frame\n",
        "# select only the columns that start with 'param_' and the column 'mean_test_score'\n",
        "grid_cv_res.filter(regex = '(^param_|mean_test_score)', axis=1).head()"
      ],
      "metadata": {
        "id": "8heqk9kbi8Ke",
        "outputId": "a75d5424-6033-4706-c982-fbb56dc14915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameter grid : \n",
            "[{'svm__C': array([1.e-03, 1.e-01, 1.e+01, 1.e+03]), 'svm__gamma': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}]\n"
          ]
        }
      ]
    }
  ]
}